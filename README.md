# ğŸš€ PySpark Learning Repository

Welcome to the **PySpark Learning Repository**, a complete hands-on collection of notebooks and scripts to help you master **Apache Spark using Python (PySpark)**.
This project covers everything from basic DataFrame operations to advanced machine learning techniques using PySparkâ€™s MLlib.

---

## ğŸ“˜ **Table of Contents**

1. [Overview](#overview)
2. [Installation](#installation)
3. [Project Structure](#project-structure)
4. [Topics Covered](#topics-covered)
5. [Usage](#usage)
6. [Example Commands](#example-commands)
7. [License](#license)

---

## ğŸ§  **Overview**

PySpark is the Python API for **Apache Spark**, a powerful distributed computing framework used for **big data processing and analytics**.
This repository provides practical examples, tutorials, and ready-to-run Jupyter notebooks to help you learn PySpark step-by-step â€” from data wrangling to building machine learning models.

---

## âš™ï¸ **Installation**

Make sure you have **Python (>=3.8)** and **Java (>=8)** installed.

### 1ï¸âƒ£ Install Spark

Download and install Apache Spark:

```bash
https://spark.apache.org/downloads.html
```

### 2ï¸âƒ£ Install Required Python Libraries

```bash
pip install pyspark jupyter pandas matplotlib seaborn
```

### 3ï¸âƒ£ Launch Jupyter Notebook

```bash
jupyter notebook
```

Then open any notebook from this repository.

---

## ğŸ“‚ **Project Structure**

```
ğŸ“¦ PySpark-Learning
 â”£ ğŸ“œ README.md
 â”£ ğŸ“œ pyspark basic introduction.ipynb
 â”£ ğŸ“œ PySpark DataFrames- Part 1.ipynb
 â”£ ğŸ“œ Pyspark Dataframe- Handling Missing Values.ipynb
 â”£ ğŸ“œ Pyspark Dataframes- Filter operation.ipynb
 â”£ ğŸ“œ Pyspark With Python-GroupBy And Aggregation.ipynb
 â”£ ğŸ“œ Example Of Pyspark ML.ipynb
 â”£ ğŸ“œ Linear Regression With Pyspark.ipynb
 â”£ ğŸ“œ test1.csv
 â”£ ğŸ“œ test2.csv
 â”£ ğŸ“œ test3.csv
 â”£ ğŸ“œ tips.csv
```

---

## ğŸ“Š **Topics Covered**

| Category                        | Description                                    |
| ------------------------------- | ---------------------------------------------- |
| ğŸ”¹ **Basics**                   | Creating Spark Sessions, DataFrames, and RDDs  |
| ğŸ”¹ **Data Cleaning**            | Handling missing values, filtering data        |
| ğŸ”¹ **Aggregation**              | Using `groupBy`, `agg`, and SQL queries        |
| ğŸ”¹ **Data Analysis**            | Sorting, joining, and transforming columns     |
| ğŸ”¹ **Machine Learning (MLlib)** | Linear Regression, feature transformation      |
| ğŸ”¹ **Performance Tips**         | Best practices for distributed data processing |

---

## ğŸ§© **Usage**

You can open and execute any notebook using Jupyter.
Each notebook is **self-contained** and includes explanations and runnable examples.

Example:

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("PySparkExample") \
    .getOrCreate()

df = spark.read.csv("data.csv", header=True, inferSchema=True)
df.show()
```

---

## ğŸ§ª **Example Commands**

### Run a notebook

```bash
jupyter notebook "PySpark DataFrames- Part 1.ipynb"
```

### Run Spark shell

```bash
pyspark
```

---

## ğŸ“˜ **Learning Goals**

* Understand distributed computing with Spark
* Learn to manipulate large datasets using DataFrames
* Explore machine learning models with MLlib
* Apply transformations, aggregations, and joins efficiently
* Practice hands-on data engineering tasks

---

## ğŸ“œ **License**

This repository is licensed under the **MIT License** â€” feel free to use, modify, and distribute for educational or personal projects.

---

## ğŸ‘¨â€ğŸ’» **Author**

**Name**
ğŸ“§ [bricezemba336@gmail.com](mailto:bricezemba336@gmail.com)
ğŸ’¼ Data Enthusiast | Machine Learning | Big Data


